{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "import foolbox\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "datapath = '/home/user/datasets/ImageNet/'\n",
    "traindir = os.path.join(datapath, 'train')\n",
    "labeldir = '/home/user/datasets/ImageNet/class_to_idx.txt'\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "#         transforms.Resize(224),\n",
    "       transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "   #      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "    #                 \t     std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "#     num_workers=1, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101 = models.resnet101(pretrained=True).eval()\n",
    "if torch.cuda.is_available():\n",
    "    resnet101 = resnet101.cuda()\n",
    "else:\n",
    "    print('===============')\n",
    "mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
    "std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
    "fmodel = foolbox.models.PyTorchModel(\n",
    "    resnet101, bounds=(0, 1), num_classes=1000, preprocessing=(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from abdm.abdm import ABDM\n",
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class 933 , ground truth class 933\n",
      "adversarial class 941\n",
      "adversarial class 941\n",
      "ori image shape is : (224, 224, 3)\n",
      "===========================================================\n",
      "begin---\n",
      "WARNING:tensorflow:From /home/lxf/App/anaconda3/envs/torch_zy/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lxf/App/anaconda3/envs/torch_zy/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast/x:0\", shape=(3, 224, 224, 3), dtype=float32) Tensor(\"spatial_transformer_0/add:0\", shape=(3, 6), dtype=float32) (224, 224)\n",
      "adversarial class 933\n",
      "ori class 933\n",
      "1\n",
      "predicted class 933 , ground truth class 933\n",
      "adversarial class 934\n",
      "adversarial class 934\n",
      "ori image shape is : (224, 224, 3)\n",
      "===========================================================\n",
      "begin---\n",
      "Tensor(\"Cast_1/x:0\", shape=(3, 224, 224, 3), dtype=float32) Tensor(\"spatial_transformer_0_1/add:0\", shape=(3, 6), dtype=float32) (224, 224)\n",
      "adversarial class 933\n",
      "ori class 933\n",
      "2\n",
      "predicted class 933 , ground truth class 933\n",
      "adversarial class 121\n",
      "adversarial class 121\n",
      "ori image shape is : (224, 224, 3)\n",
      "===========================================================\n",
      "begin---\n",
      "Tensor(\"Cast_2/x:0\", shape=(3, 224, 224, 3), dtype=float32) Tensor(\"spatial_transformer_0_2/add:0\", shape=(3, 6), dtype=float32) (224, 224)\n",
      "adversarial class 933\n",
      "ori class 933\n",
      "3\n",
      "predicted class 933 , ground truth class 933\n",
      "adversarial class 960\n",
      "adversarial class 960\n",
      "ori image shape is : (224, 224, 3)\n",
      "===========================================================\n",
      "begin---\n",
      "Tensor(\"Cast_3/x:0\", shape=(3, 224, 224, 3), dtype=float32) Tensor(\"spatial_transformer_0_3/add:0\", shape=(3, 6), dtype=float32) (224, 224)\n",
      "adversarial class 945\n",
      "ori class 933\n",
      "can not use this img\n",
      "predicted class 933 , ground truth class 933\n",
      "adversarial class 962\n",
      "adversarial class 962\n",
      "ori image shape is : (224, 224, 3)\n",
      "===========================================================\n",
      "begin---\n",
      "Tensor(\"Cast_4/x:0\", shape=(3, 224, 224, 3), dtype=float32) Tensor(\"spatial_transformer_0_4/add:0\", shape=(3, 6), dtype=float32) (224, 224)\n",
      "adversarial class 950\n",
      "ori class 933\n",
      "can not use this img\n",
      "predicted class 933 , ground truth class 933\n",
      "adversarial class 931\n",
      "adversarial class 931\n",
      "ori image shape is : (224, 224, 3)\n",
      "===========================================================\n",
      "begin---\n",
      "Tensor(\"Cast_5/x:0\", shape=(3, 224, 224, 3), dtype=float32) Tensor(\"spatial_transformer_0_5/add:0\", shape=(3, 6), dtype=float32) (224, 224)\n",
      "adversarial class 927\n",
      "ori class 933\n",
      "can not use this img\n",
      "predicted class 933 , ground truth class 933\n",
      "adversarial class 934\n",
      "adversarial class 934\n",
      "ori image shape is : (224, 224, 3)\n",
      "===========================================================\n",
      "begin---\n",
      "Tensor(\"Cast_6/x:0\", shape=(3, 224, 224, 3), dtype=float32) Tensor(\"spatial_transformer_0_6/add:0\", shape=(3, 6), dtype=float32) (224, 224)\n",
      "adversarial class 933\n",
      "ori class 933\n",
      "4\n",
      "predicted class 933 , ground truth class 933\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3ee298a6adcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdp_attack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepfool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepFoolAttack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinfinity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#dp_attack = foolbox.attacks.PGD(fmodel, distance=foolbox.distances.Linfinity)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0madversarial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdp_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adversarial class'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madversarial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App/anaconda3/envs/torch_zy/lib/python3.5/site-packages/foolbox/attacks/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, input_or_adv, label, unpack, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decorated __call__ method must return None'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopAttack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App/anaconda3/envs/torch_zy/lib/python3.5/site-packages/foolbox/attacks/deepfool.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions_and_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_adv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App/anaconda3/envs/torch_zy/lib/python3.5/site-packages/foolbox/adversarial.py\u001b[0m in \u001b[0;36mpredictions_and_gradient\u001b[0;34m(self, image, label, strict, return_details)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_prediction_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_gradient_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions_and_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         is_adversarial, is_best, distance = self.__is_adversarial(\n\u001b[1;32m    433\u001b[0m             image, predictions, in_bounds)\n",
      "\u001b[0;32m~/App/anaconda3/envs/torch_zy/lib/python3.5/site-packages/foolbox/models/pytorch.py\u001b[0m in \u001b[0;36mpredictions_and_gradient\u001b[0;34m(self, image, label)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App/anaconda3/envs/torch_zy/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App/anaconda3/envs/torch_zy/lib/python3.5/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App/anaconda3/envs/torch_zy/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App/anaconda3/envs/torch_zy/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App/anaconda3/envs/torch_zy/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App/anaconda3/envs/torch_zy/lib/python3.5/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "img_id=[]        #ori images ID list\n",
    "img_ori=[]       #ori images list\n",
    "img_adv=[]       #adv images list\n",
    "img_label=[]     #ori images labels list\n",
    "abdm_image=[]     #abdm images list  \n",
    "\n",
    "wrong_oriimg=0\n",
    "right_advimg=0\n",
    "wrong_advimg=0\n",
    "right_abdmimg=0\n",
    "wrong_abdmimg=0\n",
    "for num in range(1194000,1194100):\n",
    "    image, target = train_dataset[num]\n",
    "    image= np.array(image)\n",
    "    print('predicted class', np.argmax(fmodel.predictions(image)),', ground truth class',target)\n",
    "    tempclass1=str(np.argmax(fmodel.predictions(image)))\n",
    "    tempclass2=str(target)\n",
    "    if(tempclass1!=tempclass2):\n",
    "        wrong_oriimg=wrong_oriimg+1\n",
    "        continue\n",
    "        \n",
    "    #dp_attack = foolbox.attacks.FGSM(fmodel)\n",
    "    dp_attack = foolbox.attacks.deepfool.DeepFoolAttack(fmodel, distance=foolbox.distances.Linfinity)\n",
    "    #dp_attack = foolbox.attacks.PGD(fmodel, distance=foolbox.distances.Linfinity)\n",
    "    adversarial = dp_attack(image, target)\n",
    "    try:\n",
    "        print('adversarial class', np.argmax(fmodel.predictions(adversarial)))\n",
    "    except: \n",
    "        wrong_advimg=wrong_advimg+1\n",
    "        print('error')\n",
    "        continue\n",
    "    else:\n",
    "        right_advimg=right_advimg+1\n",
    "        print('adversarial class', np.argmax(fmodel.predictions(adversarial)))\n",
    "\n",
    "    \n",
    "    #===============abdm start (0.0)=========================================\n",
    "    im=adversarial\n",
    "    im = transform(im).numpy()\n",
    "    im = transform(im).numpy()\n",
    "    image_show=im\n",
    "    #im=im.resize(3,224,224)\n",
    "    print('ori image shape is :',im.shape)\n",
    "    print(\"===========================================================\")\n",
    "    im = im.reshape(1, 224, 224, 3)\n",
    "    im = im.astype('float32')\n",
    "    #print('img-over')\n",
    "    out_size = (224, 224)\n",
    "    batch = np.append(im, im, axis=0)\n",
    "    batch = np.append(batch, im, axis=0)\n",
    "    num_batch = 3 \n",
    "    x = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    x = tf.cast(batch, 'float32')\n",
    "    print('begin---')\n",
    "    with tf.variable_scope('spatial_transformer_0'):\n",
    "        n_fc = 6\n",
    "        w_fc1 = tf.Variable(tf.Variable(tf.zeros([224 * 224 * 3, n_fc]), name='W_fc1'))\n",
    "        initial = np.array([[0.5, 0, 0], [0, 0.5, 0]])\n",
    "        initial = initial.astype('float32')\n",
    "        initial = initial.flatten()  \n",
    "        b_fc1 = tf.Variable(initial_value=initial, name='b_fc1')   \n",
    "        h_fc1 = tf.matmul(tf.zeros([num_batch, 224 * 224 * 3]), w_fc1) + b_fc1\n",
    "        print(x, h_fc1, out_size)\n",
    "        h_trans = ABDM(x, h_fc1, out_size)\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    y = sess.run(h_trans, feed_dict={x: batch})\n",
    "    abdmimg_temp=transform(y[0]).numpy()\n",
    "    \n",
    "    adv_class=str(np.argmax(fmodel.predictions(abdmimg_temp)))\n",
    "    orilabel=str(target)\n",
    "    print('adversarial class', np.argmax(fmodel.predictions(abdmimg_temp)))\n",
    "    print('ori class', orilabel)\n",
    "    if(adv_class==orilabel):\n",
    "        # put images and labels into list\n",
    "        img_ori.append(image)\n",
    "        img_adv.append(adversarial)\n",
    "        img_label.append(target)\n",
    "        img_id.append(num)\n",
    "        abdm_image.append(abdmimg_temp)\n",
    "        print(len(img_id))\n",
    "        right_abdmimg=right_abdmimg+1\n",
    "    else:\n",
    "        print('can not use this img')\n",
    "        wrong_abdmimg=wrong_abdmimg+1\n",
    "        continue\n",
    "\n",
    "        \n",
    "ori_right=(100-wrong_oriimg)/100\n",
    "adv_right=(wrong_oriimg+wrong_advimg)/100\n",
    "abdm_right=right_abdmimg/100\n",
    "abdm_right2=right_abdmimg/(right_abdmimg+wrong_abdmimg)\n",
    "\n",
    "print('clean image accuracy:  %.2f%%' % (ori_right * 100))\n",
    "print('adv image accuracy:  %.2f%%' % (adv_right * 100))\n",
    "print('abdm image accuracy:  %.2f%%' % (abdm_right * 100 ))      \n",
    "print('abdm image accuracy:  %.2f%%' % (abdm_right2 * 100 ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_zy",
   "language": "python",
   "name": "torch_zy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
